{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    #translator = str.maketrans('', '', string.punctuation)\n",
    "    # aha,this is also because z cannot be the only argument\n",
    "    #If extra values exist as the first and second arguments, they are added to this mapping as additional \n",
    "    #characters to be translated (this is why the author selected '' and ''; he doesn't want extra characters\n",
    "    #to be translated):\n",
    "    return text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))).replace(' '*4, ' ').replace(' '*3, ' ').replace(' '*2, ' ').strip()\n",
    "\n",
    "\n",
    "baby_df = pd.read_csv('/home/user/Pulpit/pani_ela_data_science/temat4/amazon_baby.csv')\n",
    "baby_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beautiful little book A great little short story saying I Love You Keeps the attention of the baby and then the baby can actually turn the pages and hold on to it when you are finished interacting with it'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bacause of the above reason, I'll do b) first ( than a) )\n",
    "# b)\n",
    "baby_df['review'] = baby_df['review'].fillna('')\n",
    "baby_df[\"review\"][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "baby_df['review'] = baby_df['review'].apply(remove_punctuation)\n",
    "#short test: \n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All of my kids have cried non stop when I tried to ween them off their pacifier until I found Thumbuddy To Love s Binky Fairy Puppet It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it This is a must buy book and a great gift for expecting parents You will save them soo many headaches Thanks for this book You all rock'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_df[\"review\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)\n",
    "\n",
    "#short test:\n",
    "baby_df[\"review\"][38] == baby_df[\"review\"][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_df.drop(baby_df[baby_df.rating == 3].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\n",
    "#df = df.drop(df[df.score < 50].index)\n",
    "#In place version (as pointed out in comments)\n",
    "#df.drop(df[df.score < 50].index, inplace=True)\n",
    "\n",
    "#baby_df.drop(baby_df[baby_df.review == 3].index, inplace=True)\n",
    "baby_df[baby_df.rating < 3]\n",
    "\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"] == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183526</td>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183527</td>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183528</td>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183529</td>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183530</td>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166752 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "5       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \n",
       "1       it came early and was not disappointed. i love...       5  \n",
       "2       Very soft and comfortable and warmer than it l...       5  \n",
       "3       This is a product well worth the purchase.  I ...       5  \n",
       "4       All of my kids have cried non-stop when I trie...       5  \n",
       "5       When the Binky Fairy came to our house, we did...       5  \n",
       "...                                                   ...     ...  \n",
       "183526  Such a great idea! very handy to have and look...       5  \n",
       "183527  This product rocks!  It is a great blend of fu...       5  \n",
       "183528  This item looks great and cool for my kids.......       5  \n",
       "183529  I am extremely happy with this product. I have...       5  \n",
       "183530  I love this product very mush . I have bought ...       5  \n",
       "\n",
       "[166752 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d) it seems not to listen to that\n",
    "baby_df = pd.read_csv('/home/user/Pulpit/pani_ela_data_science/temat4/amazon_baby.csv')\n",
    "baby_df.drop(baby_df[baby_df.rating == 3].index, inplace=True)\n",
    "\n",
    "baby_df.loc[(baby_df.rating < 3),'rating']= -1\n",
    "#baby_df.loc[(baby_df.rating > 3),'rating']= 1\n",
    "#baby_df.loc[(baby_df.rating > 3),'rating']= 1\n",
    "baby_df[baby_df.rating == 3]\n",
    "\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"]**2 != 1)\n",
    "#print(baby_df[baby_df.rating == 1])\n",
    "baby_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adore', 'and', 'apples', 'bananas', 'dislike', 'hate', 'like', 'oranges', 'they', 'we']\n",
      "[[0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 2 1 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\"We like apples\",\n",
    "                   \"We hate oranges\",\n",
    "                   \"I adore bananas\",\n",
    "                   \"We like like apples and oranges\",\n",
    "                   \"They dislike bananas\"]\n",
    "y_train_example = [1,1,0,1,0]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X_train_example.todense())\n",
    "model_trial = LogisticRegression()\n",
    "model_trial.fit(X_train_example, y_train_example)\n",
    "# CountVectorizer przedstawia zadane zdania za pomoca ilosci pojawien w zdaniu danego wyrazu ze zlownika\n",
    "# w postaci listy\n",
    "len(model_trial.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trial.predict(np.array([0,1,1,0,0,0,2,1,0,1]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\n",
    "\n",
    "print(X_test_example.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer does not take order into account. It also does not take single letters into account.\n",
    "# For test values it ignores words which are not in its dictonary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71ba8875b8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Czyli roumiem, ze trening, ktɔry sie tutaj odbywa polega na ocenieniu czydane s᷆owo jest pozytywne czyli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Tak jest:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_vect' is not defined"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "# And it should learn which word is seen in positive reviews and which in negative\n",
    "# And based on that we should be able to know whch word is thought to appear in positive/negative reviews\n",
    "# I jako, ze to jest LogisticRegression to powinno nam jeszcze powiedziec z jakim prawdopodobienstwem\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# Czyli roumiem, ze trening, ktɔry sie tutaj odbywa polega na ocenieniu czydane s᷆owo jest pozytywne czyli\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Tak jest:\n",
    "#predict(self, X)\tPredict class labels for samples in X.\n",
    "#predict_log_proba(self, X)\tLog of probability estimates.\n",
    "#predict_proba(self, X)\tProbability estimates.\n",
    "\n",
    "# czyli moze tak przez analogi efo linear classifiers:\n",
    "# uczy sie prawdopodobienstw z jakimi kazdy z wyrazow nalezy do danej kategorii, czyli parwdopodobiestaw sa\n",
    "# dobra juz widze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-324658a2069d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-324658a2069d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Coefficient of the features in the decision function.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "Coefficient of the features in the decision function.\n",
    "Dobra - poki co nie mam odpwiedzi ani nie mam, wiec pozostaje \n",
    "\n",
    "#coef_ is of shape (1, n_features) when the given problem is binary. In particular, when multi_class=\n",
    "#'multinomial', coef_ corresponds to outcome 1 (True) and -coef_ corresponds to outcome 0 (False).\n",
    "#hint: model.coef_, vectorizer.get_feature_names()\n",
    "\n",
    "# but watch out czy te coeffcy to prawdopodobienstwa - nie zja\n",
    "\n",
    "# Aha, to bylo tak, ze w tym recznym modelu, do mnozenia - bralo sie log prawdopodobienstw, bo wtdy nie\n",
    "# wychodzily absurdalnie male liczby\n",
    "\n",
    "# model.coef_.shape - wspolczynnik dla kazdego slowa (wspolczynnik, czyli zgauje ze cos na ksztalt prawdop.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision function zwraca odleglosc do hyperplanu nie podzialu decyzji, nie wiem jak to sie ma do DOKLADNIE\n",
    "# do prawdopodobiestw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_probable_positives = []\n",
    "most_probable_negatives = []\n",
    "model_coefs = list(model.coef_[0])\n",
    "for i in range(10):\n",
    "    index_max = np.argmax(model_coefs)\n",
    "    index_min = np.argmin(model_coefs)\n",
    "    max_value = model_coefs.pop(index_max)\n",
    "    min_value = model_coefs.pop(index_min)\n",
    "    most_probable_positives.append( vectorizer.get_feature_names()[index_max] )\n",
    "    most_probable_negatives.append( vectorizer.get_feature_names()[index_min] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5f1faacfb51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# I was wandering, which coefficients 1 or 2, should be used to estimate words' probabilites.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Confidence scores per (sample, class) combination - decision function, so I guess that this function id used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_vect' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(model.decision_function(X_train_vect))) # 1 - These scores can be used to make class predictions as follows:\n",
    "print(len(model.coef_[0])) # 2\n",
    "print(np.shape(X_train_vect))\n",
    "# I was wandering, which coefficients 1 or 2, should be used to estimate words' probabilites.\n",
    "# Confidence scores per (sample, class) combination - decision function, so I guess that this function id used\n",
    "# for predictoin of samples , and I guess that coef_s are for predictions of single words\n",
    "# Coefficient of the features in the decision function. \n",
    "(X_train_vect[0].todense()[0])\n",
    "# Tak przeprowadzilas symulacje i to faktycznie coefsy odpowiadajɛ cechom\n",
    "# sigmoid( dot([val1, val2], lr.coef_) + lr.intercept_ ) \n",
    "print [1./(1+np.exp(-x)) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test_vect)\n",
    "ValueError: X has 141188 features per sample; expecting 52648\n",
    "# Aha, czyli on robi predykcje dla poszczegɔlnych slow, no ale nie no - wspolczynniki kolejnych slow sluza za \n",
    "# skladowe, sa atrybutami, i tylko powinny sluzyc do przewidywania prob.\n",
    "\n",
    "# you should build test based on train dictionary- this should solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "# no i on sie uczy prawdopodobienstw slow i na ich podstawie powienien przewidzeic zdanie- i co , i nic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "\n",
    "#hint: model.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c) \n",
    "#len(X_test.review) #55029\n",
    "#hint: use the results of b)\n",
    "\n",
    "# w liscie prawdopodobienstw bylo ponumerowane po kolei natomiast ze wzgledu na losowosc na liscie X_test\n",
    "# jest nie po kolie co moze powodowac problemy ze znakami\n",
    "\n",
    "# However, as chceked empirically, this numeration turned to be good for this example.\n",
    "# The returned estimates for all classes are ordered by the label of classes, so in this case [P(1),P(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_probab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aac1762f4f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmost_positive_rev_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmost_negative_rev_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpositive_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_probab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnegative_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_probab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_probab' is not defined"
     ]
    }
   ],
   "source": [
    "# na wszelki wypadek to zachowam jakby by᷆o zle , doprawdy nie wiem o co to chodzi z tymi pojedynczymi \n",
    "# niepasujacymi\n",
    "#len( np.sort(list(test_probab[:,0])) )\n",
    "\n",
    "most_positive_rev_ind = []\n",
    "most_negative_rev_ind = []\n",
    "positive_prob = list(test_probab[:,1])\n",
    "negative_prob = list(test_probab[:,0])\n",
    "for i in range(5):\n",
    "    max_pos_ind = np.argmax(positive_prob) \n",
    "    max_neg_ind = np.argmax(negative_prob) \n",
    "    max_pos_value = positive_prob.pop(max_pos_ind)\n",
    "    max_pos_value = negative_prob.pop(max_neg_ind)\n",
    "    most_positive_rev_ind.append(max_pos_ind)\n",
    "    most_negative_rev_ind.append(max_neg_ind)\n",
    "\n",
    "# Indices of the most positive and the most negative reviews:\n",
    "print(most_positive_rev_ind)\n",
    "print(most_negative_rev_ind)\n",
    "positive_prob[53755]\n",
    "# No ok, to mnie troche dziwi, 4 z pieciu wynikow w kazdej z kolumn sa jaknajbardziej sensowne, ale skrajne w \n",
    "# obu sa absurdalne - o co chodzi?\n",
    "# i wogogole to uzyskujac te prawdopodobienstwa przy uzyciu innej funkcji\n",
    "# okej, to moze sie zgadzac, ze wzgledu na roznice w numeracji, bo znajdowanie wartosci wykonuje sie potem \n",
    "# przy uzyciu funkcji iloc, ktora jest inclusive czy cos, ale przy wybieraniu konkretnych elementɔw to nie \n",
    "# powinno miec znaczenia\n",
    "# w sensie - positive probabs sa lista, no i ajnie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okey it makes sense, when we changed the order - it turned out that, order is different that you thought\n",
    "#before thus if we get results close to zero in first column, it means high probability of being positive\n",
    "# and results close to zero in second column - it means most negative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, most positive to tam, gdzie pierwsza kolumna dazy do zera, ok, czyli najwieksze to te najbardziej\n",
    "# negatywne, a to wynika z kolejnosci sortownia wykonywanej przez argsort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mozesz do tego wrocic, i przanalizowac caly workflow regresji logistycznej i tych wynikɔw, i czemu taki \n",
    "# odwrocony order ma miejsce, ale nie teraz, tylko w okienku, bo teraz to masz \n",
    "# zmecznie materialu z tym zwiazane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "# 3) uzywajac tego typu kodu do do skroconeg osubsetu z niewyjascnionych przyczy nie eychodzi\n",
    "# zniwu jakas zabawa z indexami, wiec juz sie tym nie baz, bo na tym etaoie to szkoda czasu\n",
    "most_probable_positives_subset = []\n",
    "most_probable_negatives_subset = []\n",
    "model_coefs_subset = list(model_subset.coef_[0])\n",
    "'''for i in range(9):\n",
    "    index_max_subset = np.argmax(model_coefs_subset)\n",
    "    index_min_subset = np.argmin(model_coefs_subset)\n",
    "    max_value_subset = model_coefs_subset.pop(index_max_subset)\n",
    "    min_value_subset = model_coefs_subset.pop(index_min_subset)\n",
    "    most_probable_positives_subset.append( vectorizer_subset.get_feature_names()[index_max_subset] )\n",
    "    most_probable_negatives_subset.append( vectorizer_subset.get_feature_names()[index_min_subset] )\n",
    "    \n",
    "print('Most probable positives:')\n",
    "print(most_probable_positives_subset)\n",
    "print('Most probavle negatives:')\n",
    "print(most_probable_negatives_subset)'''\n",
    "model_coefs_subset\n",
    "\n",
    "# Znowoz nie wiem czemu w tym przypadku sie pojebala kolejnosc ze w pierwszje kolumnie sa jednak pozytyne\n",
    "# a nie negatywne, a nie na odworɔt, ale coz\n",
    "# Poki co dajmy temu spokɔj, mozejsz wrocic do tego w okinwku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "# timeit dokonczysz na cwikach - bo to chyba nie trudne, ale zmudne\n",
    "#hint: %time, %timeit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
