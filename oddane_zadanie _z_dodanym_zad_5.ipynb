{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    '''\n",
    "    READ_ME:\n",
    "    I changed this function on purpose, because previous produce concatenated words if there was no space\n",
    "    after punctuation. I thought it could be better to keep all words sepate. That's why I get false in\n",
    "    exercise 1a.\n",
    "    '''\n",
    "    return text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))).replace(' '*4, ' ').replace(' '*3, ' ').replace(' '*2, ' ').strip()\n",
    "\n",
    "baby_df = pd.read_csv('/home/user/Pulpit/pani_ela_data_science/temat4/amazon_baby.csv')\n",
    "baby_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bacause of the above reason, I'll do b) first ( than a) )\n",
    "# b)\n",
    "baby_df['review'] = baby_df['review'].fillna('')\n",
    "baby_df[\"review\"][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "baby_df['review'] = baby_df['review'].apply(remove_punctuation)\n",
    "#short test: \n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All of my kids have cried non stop when I tried to ween them off their pacifier until I found Thumbuddy To Love s Binky Fairy Puppet It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it This is a must buy book and a great gift for expecting parents You will save them soo many headaches Thanks for this book You all rock'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_df[\"review\"][4] # explained at the very beinning of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) - done before a\n",
    "\n",
    "#short test:\n",
    "baby_df[\"review\"][38] == baby_df[\"review\"][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\n",
    "baby_df.drop(baby_df[baby_df.rating == 3].index, inplace=True)\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"] == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d) \n",
    "baby_df.rating.loc[baby_df['rating'] < 3] = -1\n",
    "baby_df.rating.loc[(baby_df['rating'] == 4)] = 1\n",
    "baby_df.rating.loc[(baby_df['rating'] == 5)] = 1\n",
    "\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"]**2 != 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adore', 'and', 'apples', 'bananas', 'dislike', 'hate', 'like', 'oranges', 'they', 'we']\n",
      "[[0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 2 1 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\"We like apples\",\n",
    "                   \"We hate oranges\",\n",
    "                   \"I adore bananas\",\n",
    "                   \"We like like apples and oranges\",\n",
    "                   \"They dislike bananas\"]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X_train_example.todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\n",
    "\n",
    "print(X_test_example.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(baby_df[['review']], baby_df[['rating']], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train.review)\n",
    "X_test_vect = vectorizer.transform(X_test.review)\n",
    "#print(X_train_vect.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111723, 52648)\n",
      "(111723, 1)\n",
      "(55029, 52648)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/user/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/user/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "# READ_ME:\n",
    "# I assume that the entries with smallest coefficients are negative, and these with largest are positive\n",
    "# Because I assume that we get a positive review if linear regression function is above threshold - wich \n",
    "# happens for numbers with large coeffibients. But what bothers me is that, for my argument to be true, I had \n",
    "# to assude that we have one linear regression curve (and assume positive to be these above threshold - but\n",
    "# in fact its arbitrary,a nd I do not know whether it is the case). This situation is not the case for classi-\n",
    "# fication example(from previous lecture) where we separately considered probability of being negative or pos.\n",
    "\n",
    "most_probable_positives = []\n",
    "most_probable_negatives = []\n",
    "model_coefs = list(model.coef_[0])\n",
    "for i in range(10):\n",
    "    index_max = np.argmax(model_coefs)\n",
    "    index_min = np.argmin(model_coefs)\n",
    "    max_value = model_coefs.pop(index_max)\n",
    "    min_value = model_coefs.pop(index_min)\n",
    "    most_probable_positives.append( vectorizer.get_feature_names()[index_max] )\n",
    "    most_probable_negatives.append( vectorizer.get_feature_names()[index_min] )\n",
    "\n",
    "#vectorizer.get_feature_names()\n",
    "#hint: model.coef_, vectorizer.get_feature_names()\n",
    "#model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable positives:\n",
      "['wonderfully', 'con', 'mino', 'lifelong', 'reach', 'save', 'meetings', 'sonongram', 'perfectionalist', 'perfe']\n",
      "Most probavle negatives:\n",
      "['dissapointed', 'worships', 'worsens', 'worsened', 'worsen', 'worse', 'worrywart', 'worrying', 'worry', 'worrth']\n"
     ]
    }
   ],
   "source": [
    "print('Most probable positives:')\n",
    "print(most_probable_positives)\n",
    "print('Most probavle negatives:')\n",
    "print(most_probable_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "test_predictions = model.predict(X_test_vect)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58123368, 0.41876632],\n",
       "       [0.84845375, 0.15154625],\n",
       "       [0.97190261, 0.02809739],\n",
       "       ...,\n",
       "       [0.45390936, 0.54609064],\n",
       "       [0.01561626, 0.98438374],\n",
       "       [0.01050695, 0.98949305]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)\n",
    "test_probab = model.predict_proba(X_test_vect)\n",
    "test_probab\n",
    "#hint: model.predict_proba()\n",
    "# The returned estimates for all classes are ordered by the label of classes, so in this case [P(-1),P(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices od most positive reviews:\n",
      "[ 4051  2724 36188  7283 46653]\n",
      "Indices od most negative reviews:\n",
      "[30933  4809 25937 53758   781]\n",
      "\n",
      "Most positive reviews:\n",
      "74899     We love this highchair We have a 4 year old an...\n",
      "114796    My husband and I cannot state enough how much ...\n",
      "22586     I researched a few different seats to put in o...\n",
      "143615    I was a little nervous about ordering this bab...\n",
      "28530     OVERVIEW My daughter has to be one of the wild...\n",
      "Name: review, dtype: object\n",
      "\n",
      "Most nagative reviews:\n",
      "147902    My disappointment with this product prompted m...\n",
      "175191    I had to return this stroller for three reason...\n",
      "57234     My husband and I are VERY disappointed and sho...\n",
      "16042     We have not had ANY luck with Fisher Price pro...\n",
      "77072     I thought it sounded great to have different t...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#c) \n",
    "#len( np.sort(list(test_probab[:,0])) )\n",
    "\n",
    "most_positive_rev_ind = []\n",
    "most_negative_rev_ind = []\n",
    "# (below I choosed revrsed order for positives and negatives for it to be compatible with a way of sorting\n",
    "# performed by argsort)\n",
    "positive_prob = list(test_probab[:,0])\n",
    "negative_prob = list(test_probab[:,1])\n",
    "\n",
    "positive_idx = np.argsort(positive_prob)[:5]\n",
    "negative_idx = np.argsort(negative_prob)[:5]\n",
    "print('Indices od most positive reviews:')\n",
    "print(positive_idx)\n",
    "print('Indices od most negative reviews:')\n",
    "print(negative_idx)\n",
    "print('')\n",
    "print('Most positive reviews:')\n",
    "print(X_test.review.iloc[positive_idx])\n",
    "print('')\n",
    "print('Most nagative reviews:')\n",
    "print(X_test.review.iloc[negative_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9315451852659506\n"
     ]
    }
   ],
   "source": [
    "#d) \n",
    "# test_predictions\n",
    "y_original = y_test.rating.tolist()\n",
    "correct_pred = np.sum(test_predictions == y_original)\n",
    "num_y = len(y_original)\n",
    "accuracy = correct_pred * 1./ num_y\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "\n",
    "# 2 repeated)\n",
    "#Exercise 2\n",
    "#a) Split dataset into training and test sets. - already splitted and I still can use this split:\n",
    "#                                                X_train, X_test, y_train, y_test\n",
    "\n",
    "#b) Transform reviews into vectors using CountVectorizer.\n",
    "vectorizer_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "X_train_vect_subset = vectorizer_subset.fit_transform(X_train['review'])\n",
    "X_test_vect_subset = vectorizer_subset.transform(X_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111723, 20)\n",
      "(111723, 1)\n",
      "(55029, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect_subset.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test_vect_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 repeated)\n",
    "#a) Train LogisticRegression model on training data (reviews processed with CountVectorizer,\n",
    "#   ratings as they were).\n",
    "#b) Print 10 most positive and 10 most negative words.\n",
    "\n",
    "#a)\n",
    "model_subset = LogisticRegression()\n",
    "model_subset.fit(X_train_vect_subset, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>loves</td>\n",
       "      <td>1.708419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>perfect</td>\n",
       "      <td>1.508035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>love</td>\n",
       "      <td>1.348906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>easy</td>\n",
       "      <td>1.169712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>great</td>\n",
       "      <td>0.911509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>well</td>\n",
       "      <td>0.516092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>little</td>\n",
       "      <td>0.514747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>able</td>\n",
       "      <td>0.209372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>car</td>\n",
       "      <td>0.083544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>old</td>\n",
       "      <td>0.056120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>less</td>\n",
       "      <td>-0.193071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>product</td>\n",
       "      <td>-0.311377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>would</td>\n",
       "      <td>-0.352728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>even</td>\n",
       "      <td>-0.497453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>work</td>\n",
       "      <td>-0.625374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>money</td>\n",
       "      <td>-0.921791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>broke</td>\n",
       "      <td>-1.627293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>waste</td>\n",
       "      <td>-1.974542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>return</td>\n",
       "      <td>-2.100428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>-2.400153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficient\n",
       "6          loves     1.708419\n",
       "5        perfect     1.508035\n",
       "0           love     1.348906\n",
       "2           easy     1.169712\n",
       "1          great     0.911509\n",
       "7           well     0.516092\n",
       "4         little     0.514747\n",
       "8           able     0.209372\n",
       "9            car     0.083544\n",
       "3            old     0.056120\n",
       "11          less    -0.193071\n",
       "16       product    -0.311377\n",
       "18         would    -0.352728\n",
       "12          even    -0.497453\n",
       "15          work    -0.625374\n",
       "17         money    -0.921791\n",
       "10         broke    -1.627293\n",
       "13         waste    -1.974542\n",
       "19        return    -2.100428\n",
       "14  disappointed    -2.400153"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_subset_coef_table = pd.DataFrame({'word':significant_words,\n",
    "                                         'coefficient':model_subset.coef_.flatten()})\n",
    "\n",
    "# In this case there is no point in dividing them, because there are only 20 elements, so first we can \n",
    "# consider first 10 as positive and the rest (10) as negative.\n",
    "model_subset_coef_table.sort_values(['coefficient'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeated 4)\n",
    "#a) Predict the sentiment of test data reviews.\n",
    "#b) Predict the sentiment of test data reviews in terms of probability.\n",
    "#c) Find five most positive and most negative reviews.\n",
    "#d) Calculate the accuracy of predictions.\n",
    "\n",
    "\n",
    "#a) \n",
    "test_predictions_subset = model_subset.predict(X_test_vect_subset)\n",
    "test_predictions_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07798563, 0.92201437],\n",
       "       [0.21411052, 0.78588948],\n",
       "       [0.21411052, 0.78588948],\n",
       "       ...,\n",
       "       [0.27936853, 0.72063147],\n",
       "       [0.05826628, 0.94173372],\n",
       "       [0.09150662, 0.90849338]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)\n",
    "test_probab_subset = model_subset.predict_proba(X_test_vect_subset)\n",
    "test_probab_subset\n",
    "#hint: model.predict_proba()\n",
    "# The returned estimates for all classes are ordered by the label of classes, so in this case [P(-1),P(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices od most positive reviews:\n",
      "[ 9950 25449 17088 39352 52148]\n",
      "Indices od most negative reviews:\n",
      "[49840 38872 52905 34148 49479]\n",
      "\n",
      "Most positive reviews:\n",
      "41581     Looks really cute however the cloth smells fun...\n",
      "168391    I loved all the features of the car seat It is...\n",
      "50968     Besides the fact that the sensory balls arrive...\n",
      "35763     Day 1 Assembled it Had it up and running playi...\n",
      "56798     I was excited to give these instruments to my ...\n",
      "Name: review, dtype: object\n",
      "\n",
      "Most nagative reviews:\n",
      "47813     Check and recheck the K Tan for size issues be...\n",
      "116072    I ve posted an UPDATE at the end First let me ...\n",
      "181635    As parents of two little ones I d like to say ...\n",
      "25525     We bought this stroller about 2 weeks ago I ab...\n",
      "144112    Background I ve been using Grovia diapers for ...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "most_positive_rev_ind_subset = []\n",
    "most_negative_rev_ind_subset = []\n",
    "# (below I choosed revrsed order for positives and negatives for it to be compatible with a way of sorting\n",
    "# performed by argsort)\n",
    "positive_prob_subset = list(test_probab_subset[:,1])\n",
    "negative_prob_subset = list(test_probab_subset[:,0])\n",
    "\n",
    "positive_idx_subset = np.argsort(positive_prob_subset)[:5]\n",
    "negative_idx_subset = np.argsort(negative_prob_subset)[:5]\n",
    "print('Indices od most positive reviews:')\n",
    "print(positive_idx_subset)\n",
    "print('Indices od most negative reviews:')\n",
    "print(negative_idx_subset)\n",
    "print('')\n",
    "print('Most positive reviews:')\n",
    "print(X_test.review.iloc[positive_idx_subset])\n",
    "print('')\n",
    "print('Most nagative reviews:')\n",
    "print(X_test.review.iloc[negative_idx_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8678333242472152\n"
     ]
    }
   ],
   "source": [
    "# test_predictions_subset\n",
    "# y_original, num_y - already defined in previous exercise\n",
    "correct_pred_subset = np.sum(test_predictions_subset == y_original)\n",
    "accuracy_subset = correct_pred_subset * 1./ num_y\n",
    "print(accuracy_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b) # I do not understand what does impact mean- I would say that it is described by coefficients\n",
    "    # already printed i in (5a repeaded 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/user/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "test_predictions_subset_train = model_subset.predict(X_train_vect_subset)\n",
    "test_predictions_subset_train = model_subset.predict(X_train_vect_subset)\n",
    "\n",
    "correct_pred_train = np.sum(test_predictions_subset_train == y_original)\n",
    "accuracy_train = correct_pred_train * 1./ num_y\n",
    "\n",
    "correct_pred_subset_train = np.sum(test_predictions_subset_train == y_original)\n",
    "accuracy_subset_train = correct_pred_subset_train * 1./ num_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for bigger dictionary: 0.9315451852659506\n",
      "Accuracy for smaller dictionary: 0.8678333242472152\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "print('Accuracy for bigger dictionary: {}'.format(accuracy))\n",
    "print('Accuracy for smaller dictionary: {}'.format(accuracy_subset))\n",
    "\n",
    "#hint: %time, %timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
